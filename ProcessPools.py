'''
This file contains the Manager Classes which handle the parts of Update process:
extracting from cab files, updating the database and searching for symbols
'''
#***************************************
# Imports
#***************************************
import queue

import os

from time import time

import threading

import subprocess

import traceback as tb

from concurrent.futures import ProcessPoolExecutor

from pathlib import Path

from shutil import rmtree

import globs

from db import wsuse_db

from support.utils import dbgmsg, validatecab, ispe, validatezip, \
    getfilehashes, ispebuiltwithdebug, pebinarytype, getpepdbfilename, \
    getpeage, getpearch, getpesigwoage, ispedbgstripped

from dependencies.pefile import pefile

#****************************************************
# Classes
#****************************************************
class ExtractMgr(threading.Thread):
    '''
    pdir - directory to cab files to be extracted
    dest - directory to place extracted results
    poolsize - number of processes to spawn and keep track of
    cleaner - CleanMgr to pass results to
    db - DBMgr for which to refer database write jobs to
    '''
    def __init__(self, pdir, dest, poolsize, cleaner, db, local):
        super(ExtractMgr, self).__init__()
        self.pdir = pdir
        self.dest = dest
        self.poolsize = poolsize
        self.cleaner = cleaner
        self.dbc = db
        # jobs - a list of cab files that have not been distributed to worker processes
        self.jobs = []
        # workRemaining - the amount of work that is not complete, which is not strictly the
        # same as the length of the jobs list, since work remaining includes jobs taken off
        # of the list to be worked on by processes
        self.workremaining = 0
        # jobsincoming - an event to signal to the ProcessPoolExecutor that more jobs have
        # been added to the jobs list
        self.jobsincoming = threading.Event()
        self.localaction = local

    def addq(self, taskpath):
        '''
        adds item to job list from which the manager will task workers with
        '''
        self.jobs.append(taskpath)
        self.jobsincoming.set()
        self.workremaining += 1

    def passresult(self, future):
        '''
        takes future generated by executor process and passes result to
        cleaner
        '''
        # if exception generated by extracttask, notify here. If not, get result and send to
        # cleaner
        fexception = future.exception()
        if fexception:
            dbgmsg("[EXMGR] {-} exception occurred: " + str(fexception) + \
            "\ntraceback: " + tb.format_exc())
        else:
            job = future.result()
            if job is not None:
                # if the directory contains ncabdir, then we
                # know that it is already a nestedCab, so remove
                # it from deliverables, otherwise, send to DBMgr
                ncabdir = self.pdir + "\\nestedCabs"
                if ncabdir in job[0][0]:
                    dbgmsg("[EXMGR] found nested cab, not adding to database")
                else:
                    self.dbc.addtask("update", job[0], job[1], job[2], None)

                if self.cleaner is not None:
                    self.cleaner.receivejobset(job[0][0])
                    dbgmsg("[EXMGR] sent to cleaner: " + str(job[0][0]))
                else:
                    dbgmsg("[EXMGR] no jobs passed to cleaner")
            else:
                dbgmsg("[EXMGR] job did not contain patched binaries or additional updates")

        # if there are no more nested cabs, set the jobsincoming event to allow thread to
        # complete execution
        self.workremaining -= 1
        dbgmsg("[EXMGR] work remaining: " + str(self.workremaining))
        if self.workremaining == 0:
            self.jobsincoming.set()

    def requeuetask(self, future):
        '''
        if extraction yielded additional cabs, add those tasks back into job list
        '''
        job = future.result()
        if not job is None:
            if job[0][1]:
                for task in job[0][1]:
                    if validatecab(task):
                        self.addq(task)

    def run(self):
        '''
        ExtractMgr finds all cab files in target directory and adds to jobslist.
        Then assigns jobslist items to worker processes which handle extraction/DB update.
        Finally receives results back from workers, requeues nested cabs if any,
        and passes results to cleaner.
        '''
        start = time()
        dbgmsg("[EXMGR] starting ExMgr")
        # search for and add cab files to task queue
        for root, dummy, files, in os.walk(self.pdir):
            for file in files:
                filel = file.lower()
                if filel.endswith(".cab") or filel.endswith(".msu") \
                    or filel.endswith(".exe"):
                    self.addq(os.path.join(root, file))

        # don't wait for results to pile up, task workers and send off to cleaner
        # and dbc as they come in.
        with ProcessPoolExecutor(max_workers=self.poolsize) as executor:
            while self.workremaining > 0:
                if not self.jobs:
                    dbgmsg("[EXMGR] waiting for more extraction jobs. Current jobs:"    \
                            + str(self.workremaining))
                    self.jobsincoming.wait()
                while self.jobs:
                    dbgmsg("[EXMGR] assigning extraction job")
                    if self.localaction:
                        future = executor.submit(self.dbupdate, self.jobs.pop(), \
                                                 self.dest)
                    else:
                        future = executor.submit(self.extracttask, self.jobs.pop(), \
                                                 self.pdir, self.dest)
                    dbgmsg("[EXMGR] jobs left: " + str(len(self.jobs)) + " " + \
                           "workremaining " + str(self.workremaining))
                    future.add_done_callback(self.requeuetask)
                    future.add_done_callback(self.passresult)

                self.jobsincoming.clear()

        dbgmsg("[EXMGR] **************part 1 done**********************")

        if self.cleaner is not None:
            self.cleaner.donesig()
        dbgmsg("[EXMGR] done signal sent to cleaner")
        self.dbc.donesig()

        end = time()
        elapsed = end-start
        print("elapsed time for part 1: " + str(elapsed))

        # clean up the nestedCabs directory if it was created
        ncabdir = self.pdir + "\\nestedCabs"
        print("cleaning up nestedCabs directory")
        try:
            rmtree(ncabdir)
        except FileNotFoundError:
            print("ncabdir: " + str(ncabdir) +  " does not exist")

    @staticmethod
    def verifyentry(src, sha256, sha512):
        '''
        verify DB entry
        '''
        dbgmsg("[EXMGR] Verifying entry for " + src)
        filepath = str(Path(src).resolve())

        if wsuse_db.dbentryexist(globs.DBCONN.cursor(),     \
                                globs.UPDATEFILESDBNAME, sha256, sha512):
            dbgmsg("[EXMGR] item " + filepath + " already exists in db, skipping")
            return False
        return True

    @staticmethod
    def performcablisting(src):
        '''
        Call expand.exe to get a listing of files within a CAB/MSU
        '''
        result = None
        dbgmsg("[EXMGR] Listing " + str(src) + " CAB contents")
        try:
            result = subprocess.check_output(
                ["expand.exe", "-D", src], shell=False)
        except subprocess.CalledProcessError as error:
            dbgmsg("[EXMGR] {-} Listing contents of " + src +
                   " failed with " + str(error.returncode) + " " +  \
            str(error.stderr))

        return result

    @staticmethod
    def performcabextract(extstr, src, newdir):
        '''
        Call expand.exe to extract files (if any)
        '''
        result = None
        try:
            dbgmsg("[EXMGR] extracting " + extstr + " at " + newdir)
            result = subprocess.check_output(
                ["expand", "-R",
                 src, "-F:" + extstr, newdir], shell=False)
            dbgmsg("[EXMGR] extracted " + extstr + " at " + newdir)
        except subprocess.CalledProcessError as error:
            dbgmsg("[EXMGR] {-} extracting " + extstr + " from " + src +    \
                    " failed with " + str(error.returncode) + " " +  \
                    error.output.decode('ascii') + ".\n\n" + \
                    "{-} cmd (" + str(error.cmd) + ") stderr (" + \
                    str(error.stderr) + ")")

        return result

    @staticmethod
    def perform7zextract(src, newpath):
        '''
        Call 7z.exe to extract files (if any)
        '''
        result = None
        dbgmsg("[EXMGR] Performing 7z on " + newpath)
        try:
            result = subprocess.check_output(["C:\\Program Files\\7-Zip\\7z.exe", "x",
                                              "-aoa",
                                              "-o" + newpath + "", "-y", src],
                                             shell=False)
            dbgmsg("[EXMGR] extracted all files within EXE")
        except subprocess.CalledProcessError as error:
            dbgmsg("[EXMGR] {-} extracting, using 7z, from " + src +
                   " failed with " + str(error.returncode) + " " +  \
                    error.output.decode('ascii'))
        return result

    @classmethod
    def dbupdate(cls, src, pdestdir):
        '''
        when given a directory of updates (CABs/MSUs/ZIPs)
        and no extraction, only set up update files to be added to dbc.
        Destination is where patched files are.
        '''

        dbgmsg("[EXMGR][DBUP] starting on " + str(src))

        # initialize deliverables
        deliverables = None
        newpath = ''

        hashes = getfilehashes(src)

        if hashes is None:
            return hashes

        if not (validatecab(str(src)) or ispe(str(src)) or validatezip(str(src))):
            dbgmsg("[EXMGR][DBUP] invalid cab/pe/zip")
            return deliverables

        newname = src.split("\\")[-1].lstrip()
        newpath = pdestdir + "\\" + newname

        if ".exe" in newname:
            newpath = newpath.split(".exe")[0]
        elif ".cab" in newname:
            newpath = newpath.split(".cab")[0]
        elif ".zip" in newname:
            newpath = newpath.split(".zip")[0]

        deliverables = ((newpath, []), hashes[0], hashes[1])
        # No need to locate nested CABs/MSUs as long the parent update file
        # is found. Revisit if needed

        dbgmsg("[EXMGR][DBUP] Extraction (DB update only) task completed for " + src)

        # Send the job to the next manager (DB will be updated eventually)
        return deliverables

    @classmethod
    def extracttask(cls, src, pdir, dst):
        '''
        task for workers to extract contents of .cab file and return
        directory of result to for use by cleaner
        '''

        hashes = getfilehashes(src)

        if hashes is None:
            return hashes

        entryexists = False
        if not cls.verifyentry(src, hashes[0], hashes[1]):
            entryexists = True

        dbgmsg("[EXMGR] started on " + str(src) + " extracting files to " +
               str(dst))

        # initialize deliverables
        deliverables = None

        newname = src.split("\\")[-1].lstrip()

        # If the files being worked on is a PE file
        # see if it can be opened with 7z.exe and that
        # it has PE files. Otherwise, skip to other
        # update files.
        if ispe(src):
            dbgmsg("[EXMGR] extracting PE file...")

            newdir = (dst + "\\" + newname).split(".exe")[0]
            try:
                os.mkdir(newdir)
            except FileExistsError:
                pass

            if not entryexists and cls.perform7zextract(src, newdir) is None:
                return deliverables

            deliverables = ((newdir, [src]), hashes[0], hashes[1])
        else:

            if not validatecab(str(src)):
                dbgmsg("[EXMGR] invalid file")
                return None

            # make new directory to hold extracted files

            newdir = (dst + "\\" + newname).split(".cab")[0]
            try:
                os.mkdir(newdir)
            except FileExistsError:
                pass

            if not entryexists:
                # extract .dll, .exe and .sys first
                cls.performcabextract("*.dll", src, newdir)
                cls.performcabextract("*.exe", src, newdir)
                cls.performcabextract("*.sys", src, newdir)

            # if nothing was extracted, remove the directory to clean up
            try:
                os.rmdir(newdir)
            except OSError:
                pass

            # prep deliverables for return
            deliverables = ((newdir, []), hashes[0], hashes[1])

            # search through rest of .cab for nested cabs or msus to extract
            # again
            if not entryexists:
                listing = cls.performcablisting(src)

                if listing is None:
                    return deliverables

                stroutput = listing.decode("ascii").split("\r\n")

                for line in stroutput:
                    if line.endswith(".cab") or line.endswith(".msu"):

                        # expand that line only to start another thread on it
                        potentialfile = line.split(":")[-1].lstrip()

                        # make a new directory to store the nested cab
                        # nested cabs with the same name may exists, keep contents
                        # under the newly created extracted directory for update
                        ncabdir = pdir + "\\nestedCabs"

                        if not os.path.exists(ncabdir):
                            try:
                                os.mkdir(ncabdir)
                                ncabdir = Path(ncabdir).resolve()

                            except OSError as error:
                                dbgmsg("[EXMGR] {-} unable to make nested cab directory: " + str(error))
                                break

                        extractstdout = cls.performcabextract(potentialfile, src, str(ncabdir))

                        if not extractstdout is None:
                            # Case where there exists nested cabs with a .manifest file
                            newpath = None
                            for root, dummy, cabs in os.walk(ncabdir):
                                for cab in cabs:
                                    if str(cab) == potentialfile:
                                        newpath = Path(os.path.join(root, cab)).resolve()
                                        break

                            if newpath is None:
                                continue

                            # if file is not a cab/msu, remove it since that's all we're interested
                            # in at this point
                            if not validatecab(str(newpath)):
                                dbgmsg("[EXMGR] {-} extracttask: " + str(newpath) + " extracted from " + \
                                    str(src) +  " is not a validate cab")
                                try:
                                    dbgmsg("[EXMGR] extracttask: Removing " + str(newpath))
                                    os.remove(newpath)
                                except FileNotFoundError as ferror:
                                    dbgmsg("[EXMGR] {-} extracttask couldn't remove " + str(newpath) + " " + \
                                        str(ferror.strerror) + " (" + str(ferror.winerror) + \
                                        ")")
                                continue

                            dbgmsg("[EXMGR] Creating " + str(newpath) + " for new thread...")

                            # return new location of extracted cab for addition to job queue
                            deliverables[0][1].append(str(newpath))

        dbgmsg("[EXMGR] Extraction task completed for " + src)
        return deliverables


class CleanMgr(threading.Thread):
    '''
    after extraction is complete sorts through collected files and removes those that
    are already in the database. Finally passes remaining files to SymMgr for Symbol
    collection.
    poolsize - number of worker processes to spawn
    symmgr - SymbolMgr to pass results to
    db - DBMgr for which to refer database write jobs to
    '''
    def __init__(self, poolsize, symmgr, db):
        super(CleanMgr, self).__init__()
        self.poolsize = poolsize
        self.symmgr = symmgr
        self.dbc = db
        # jobs - holds the paths to the directories containing binaries to sort and
        # clean up
        self.jobs = []
        # jobsready is an event to indicate that ExtractMgr has job items ready
        self.jobsready = threading.Event()
        # alldone is a signal to indicate that ExtractMgr has completed and will not send
        # any more jobs over
        self.alldone = False

    def receivejobset(self, cleaningjobs):
        '''
            receive jobs from ExtractMgr, add those jobs to jobs List, and set
        the jobsready Event to indicate there are jobs waiting to be
        processed
        '''
        self.jobs.append(cleaningjobs)
        self.jobsready.set()

    def donesig(self):
        '''
        Used to notify that there are no more jobs coming in from ExtractMgr
        so the last batch of work should proceed
        '''
        self.alldone = True
        self.jobsready.set()

    def passresult(self, future):
        '''
        takes a future generated by the executor and passes result over to
        SymbolMgr for processing. Since result is guaranteed to be new to DB
        at this point, also submits result to DBMgr to update DB
        '''
        fexception = future.exception()
        if fexception:
            dbgmsg("[CLNMGR] {-} exception occurred: " + str(fexception) + \
            "\ntraceback: " + tb.format_exc())
        else:
            result = future.result()
            if not result is None:
                if ispebuiltwithdebug(str(result[0][0])) and self.symmgr is not None:
                    # only need to use ispebuiltwithdebug here because that condition
                    # takes precedence over the stripped condition and if the item is
                    # stripped, a check must be made by symchk anyway to find the .dbg
                    # file.
                    # refer to:
                    # https://docs.microsoft.com/en-us/windows-hardware/drivers
                    # /debugger/symchk-command-line-options
                    # in the DBG file options.
                    self.symmgr.receivejobset(str(result[0][0]))
                    dbgmsg("[CLNMGR] items passed to symmgr: " + str(result[0][0]))
                # set up infolist to pass to DBMgr
                infolist = {
                    'OriginalFilename': '', 'FileDescription': '', 'ProductName': '',
                    'Comments': '', 'CompanyName': '', 'FileVersion': '',
                    'ProductVersion': '', 'IsDebug': '', 'IsPatched': '',
                    'IsPreReleased': '', 'IsPrivateBuild': '', 'IsSpecialBuild': '',
                    'Language': '', 'PrivateBuild': '', 'SpecialBuild': ''
                    }

                try:
                    unpefile = pefile.PE(result[0][0])
                except pefile.PEFormatError as peerror:
                    dbgmsg("[WSUS_DB] skipping due to exception: " + peerror.value)
                    return False

                infolist['fileext'], infolist['stype'] = pebinarytype(unpefile)
                infolist['arch'] = getpearch(unpefile)
                infolist['signature'] = getpesigwoage(unpefile)
                infolist['age'] = getpeage(unpefile)
                infolist['pdbfilename'] = getpepdbfilename(unpefile)
                infolist['strippedpe'] = ispedbgstripped(result[0][0])
                infolist['builtwithdbginfo'] = ispebuiltwithdebug(result[0][0])

                versioninfo = getattr(unpefile, "VS_VERSIONINFO", None)
                if versioninfo is not None:
                    fileinfo = getattr(unpefile, "FileInfo", None)
                    if fileinfo is not None:
                        for fileentry in unpefile.FileInfo:
                            stringtable = getattr(fileentry, "StringTable", None)
                            if stringtable is not None:
                                for strtable in fileentry.StringTable:
                                    # Currently only handling unicode en-us
                                    if strtable.LangID[:4] == b'0409' or \
                                            (strtable.LangID[:4] == b'0000' and
                                            (strtable.LangID[4:] == b'04b0' or
                                            strtable.LangID[4:] == b'04B0')):
                                        infolist["Language"] \
                                            = strtable.LangID.decode("utf-8")
                                        for field, value in strtable.entries.items():
                                            dfield = field.decode('utf-8')
                                            dvalue = value.decode('utf-8')
                                            if dfield == "OriginalFilename":
                                                infolist["OriginalFilename"] \
                                                    = dvalue
                                            if dfield == "FileDescription":
                                                infolist["FileDescription"] \
                                                    = dvalue
                                            if dfield == "ProductName":
                                                infolist["ProductName"] \
                                                    = dvalue
                                            if dfield == "Comments":
                                                infolist["Comments"] \
                                                    = dvalue
                                            if dfield == "CompanyName":
                                                infolist["CompanyName"] \
                                                    = dvalue
                                            if dfield == "FileVersion":
                                                infolist["FileVersion"] \
                                                    = dvalue
                                            if dfield == "ProductVersion":
                                                infolist["ProductVersion"] \
                                                    = dvalue
                                            if dfield == "IsDebug":
                                                infolist["IsDebug"] \
                                                    = dvalue
                                            if dfield == "IsPatched":
                                                infolist["IsPatched"] \
                                                    = dvalue
                                            if dfield == "IsPreReleased":
                                                infolist["IsPreReleased"] \
                                                    = dvalue
                                            if dfield == "IsPrivateBuild":
                                                infolist["IsPrivateBuild"] \
                                                    = dvalue
                                            if dfield == "IsSpecialBuild":
                                                infolist["IsSpecialBuild"] \
                                                    = dvalue
                                            if dfield == "PrivateBuild":
                                                infolist["PrivateBuild"] \
                                                    = dvalue
                                            if dfield == "SpecialBuild":
                                                infolist["SpecialBuild"] \
                                                    = dvalue
                if infolist['ProductName'].find("Operating System") != -1:
                    infolist['osver'] = "NT" + infolist['ProductVersion']
                else:
                    infolist['osver'] = "UNKNOWN"

                self.dbc.addtask("binary", result[0], result[1], result[2], infolist)

    def run(self):
        '''
        spawns, manages, and tasks workers to perform cleaning functionalities
        '''
        dbgmsg("[CLNMGR] ClnMgr starting")
        start_time = time()
        # setup workers and Executor
        with ProcessPoolExecutor(max_workers=self.poolsize) as executor:
            while not self.alldone:
                if not self.jobs:
                    dbgmsg("[CLNMGR] waiting for more cleaning jobs")
                    self.jobsready.wait()

                # take item from jobs and assign it to a worker
                while self.jobs:
                    jobdir = self.jobs.pop(0)
                    for root, dummy, files in os.walk(jobdir):
                        for file in files:
                            dbgmsg("[CLNMGR] assigning cleaning job for " + file)
                            filepath = Path(os.path.join(root, file)).resolve()
                            future = executor.submit(self.cleantask, filepath)
                            future.add_done_callback(self.passresult)

                self.jobsready.clear()

                dbgmsg("[CLNMGR] items left in cleanmgr queue: " + str(len(self.jobs)))

        dbgmsg("[CLNMGR] *************part 2 done*****************")

        if self.symmgr is not None:
            self.symmgr.donesig()
        dbgmsg("[CLNMGR] done signal sent to symmgr")
        self.dbc.donesig()

        endtime = time()
        elapsedtime = endtime-start_time
        print("elapsed time for part 2: " + str(elapsedtime))

    @classmethod
    def cleantask(cls, jobfile):
        '''
        task to clean up folder before submitting jobs for symbol search
        if item is removed in cleaning, None is returned, else return item
        '''
        results = None
        if ispe(jobfile):
            # check db to see if job already exists:
            hashes = getfilehashes(jobfile)

            if hashes is None:
                return hashes

            # if PE is already in db with symbols obtained,
            # do not retask job to symbol manager, otherwise continue normally
            if wsuse_db.dbentryexistwithsymbols(globs.DBCONN.cursor(),     \
                                    globs.PATCHEDFILESDBNAME, hashes[0], hashes[1]):
                return results # is None at this point in time
            else:
                dbgmsg("[CLNMGR] continuing forward with " + str(jobfile))

            # getting to this point means item is not in db, may need to come up
            # with case where db needs to update item though
            results = ((str(jobfile), None), hashes[0], hashes[1])
            dbgmsg("[CLNMGR] completed one cleantask")
        else:
            # if jobfile is not a PE, then check if it's a cab. If not a cab, remove it.
            if not validatecab(str(jobfile)):
                dbgmsg("[CLNMGR] cleantask: Removing " + str(jobfile))
                os.remove(jobfile)
                dbgmsg("[CLNMGR] " + str(jobfile) + " removed, not PE or cab file")
            else:
                dbgmsg("[CLNMGR] " + str(jobfile) + " is nested cab, skipping")
            return results

        return results


class SymMgr(threading.Thread):
    '''
    poolsize - number of worker processes to spawn
    symserver - Symbol Server with which to refer to when using symchk
    symdest - destination folder for symbols if downloading new symbols
    dbc - DBMgr for which to refer database write jobs to
    '''
    def __init__(self, poolsize, symserver, symdest, db, symlocal=False):
        super(SymMgr, self).__init__()
        self.poolsize = poolsize
        self.symserver = symserver
        self.symdest = symdest
        self.dbc = db
        self.symlocal = symlocal
        # jobs - contains the list of files to search for symbols for
        self.jobs = []
        # jobsready - an Event that indicates to SymMgr when jobs are ready
        # for it to process
        self.jobsready = threading.Event()
        # alldone - a signal that indicates to SymMgr when CleanMgr has completed
        # and will not send any more requests
        self.alldone = False

    def donesig(self):
        '''
        Used to notify that there are no more jobs coming in from CleanMgr
        so the last batch of work should proceed
        '''
        self.alldone = True
        self.jobsready.set()

    def receivejobset(self, job):
        '''
        receive jobs from CleanMgr, add those jobs to jobs List, and set
        the jobsready Event to indicate there are jobs waiting to be
        processed
        '''
        if not job is None:
            self.jobs.append(job)
            self.jobsready.set()

    def makedbrequest(self, future):
        '''
        once Symbols found, submit task to DBMgr to update database with found symbols
        '''
        fexception = future.exception()
        if fexception:
            dbgmsg("[SYMMGR] {-} exception occurred: " + str(fexception) + "\ntraceback: " + \
                tb.format_exc())
        else:
            results = future.result()
            if results is not None:
                infolist = {}

                try:
                    unpefile = pefile.PE(results[0][0])
                except pefile.PEFormatError as peerror:
                    dbgmsg("[WSUS_DB] Caught: PE error " + str(peerror) + ". File: " + results[0][0])
                    return False

                infolist['signature'] = getpesigwoage(unpefile)
                infolist['arch'] = getpearch(unpefile)

                self.dbc.addtask("symbol", results[0], results[1], results[2], infolist)
            else:
                dbgmsg("[SYMMGR] no symbols found")

    def run(self):
        '''
        spawns, manages, and tasks workers to perform cleaning functionalities
        '''
        start_time = time()
        # setup workers and Executor
        with ProcessPoolExecutor(max_workers=self.poolsize) as executor:
            while not self.alldone:
                if not self.jobs:
                    dbgmsg("[SYMMGR] waiting for more symbols jobs")
                    self.jobsready.wait()

                # take item from jobs and assign to workers
                while self.jobs:
                    dbgmsg("[SYMMGR] assigning symbol job")
                    future = executor.submit(self.symtask, self.jobs.pop(), self.symserver, \
                        self.symdest, self.symlocal)
                    future.add_done_callback(self.makedbrequest)

                self.jobsready.clear()

                dbgmsg("[SYMMGR] items left in symmgr queue: " + str(len(self.jobs)))

        dbgmsg("[SYMMGR] *************part 3 done*****************")

        self.dbc.donesig()

        endtime = time()
        elapsedtime = endtime-start_time
        print("elapsed time for part 3: " + str(elapsedtime))

    @classmethod
    def symtask(cls, jobfile, symserver, symdest, symlocal):
        '''
        perform symbol search for symbols of jobfile. If there are no symbols or symbols found
        are already in db, discard results. Else, return found symbols
        '''
        hashes = getfilehashes(jobfile)

        if hashes is None:
            return hashes

        # Check if PE file's symbols were obtained
        if wsuse_db.dbentryexistwithsymbols(globs.DBCONN.cursor(),     \
                                globs.PATCHEDFILESDBNAME, hashes[0], hashes[1]):
            return None

        result = None
        dbgmsg("[SYMMGR].. Getting SYM for (" + str(jobfile) + ")")
        servers = ""

        if symlocal:
            servers = " "+ symdest
        else:
            servers = "u \"srv*" + symdest + "*" + symserver +"\""

        args = ("symchk.exe /v \"" + str(jobfile) + "\" /s" + servers + " /od")

        with subprocess.Popen(args, shell=False, stdout=subprocess.PIPE, stderr=subprocess.PIPE) \
                as psymchk:
            # communicate used as symchk's output is for one file and
            # is not "large or unlimited"
            pstdout, pstderr = psymchk.communicate()
            stdoutsplit = str(pstdout.decode("ascii")).split("\r\n")
            stderrsplit = str(pstderr.decode("ascii")).split("\r\n")

            dbgmsg("[SYMMGR] Attempt to obtain symbols for " + str(jobfile) + " complete")

            stderrsplit.append(symserver)
            result = ((str(jobfile), stderrsplit, stdoutsplit), hashes[0], hashes[1])

        dbgmsg("[SYMMGR] completed symtask for " + str(jobfile))
        return result


class DBMgr(threading.Thread):
    '''
    handles all write transactions to db. other managers needing to write to db will
    submit request to DBmgr which will accept and perform transaction to prevent race
    conditions.
    dbConn - sqlite3 connection to database
    '''
    def __init__(self, dbconn=None):
        super(DBMgr, self).__init__()
        self.dbconn = dbconn
        # jobqueue - queue to hold database write tasks
        self.jobqueue = queue.Queue()
        # jobsig - event that indicates when there are jobs that are waiting to be processed
        self.jobsig = threading.Event()
        # donecount - used to indicate when there are no more jobs being submit to the DBMgr
        # by any of the other 3 Mgrs. When count is 3, indicates that there are no more jobs
        self.donecount = 0
        self.dbrecordscnt = 0

    def addtask(self, optype, jobtuple, sha256, sha512, infolist):
        '''
        takes results generated from other Mgrs and creates a task which is placed
        in the Queue
        '''
        task = (optype, jobtuple, sha256, sha512, infolist)
        self.jobqueue.put(task)
        dbgmsg("[DBMGR] " + optype + " task added to queue. Queue at " + \
               str(self.jobqueue.qsize()) + " tasks.")
        self.jobsig.set()

    def writeupdate(self, file, sha256, sha512):
        '''
        performs writes to DB for Update files
        should use function in wsuse_db
        '''
        dbgmsg("[DBMGR] writing update for (" + str(file) + ")")
        wsuse_db.writeupdate(file, sha256, sha512, conn=self.dbconn)

    def writebinary(self, file, sha256, sha512, infolist):
        '''
        performs write updates to db for Binary files
        should use function in wsuse_db
        '''
        dbgmsg("[DBMGR] writing binary for (" + str(file) + ")")
        wsuse_db.writebinary(file, sha256, sha512, infolist, conn=self.dbconn)

    def writesym(self, file, symchkerr, symchkout, sha256, sha512, infolist):
        '''
        performs write updates to db for Symbol Files
        should use function in wsuse_db
        '''
        dbgmsg("[DBMGR] writing symbol for (" + str(file) + ")")

        wsuse_db.writesymbol(file, symchkerr, symchkout, sha256, sha512, infolist, conn=self.dbconn)

    def donesig(self):
        '''
        When all other Mgrs are done working, set jobsig so DBMgr can handle
        rest of items in queue and complete
        '''
        self.donecount += 1
        if self.donecount >= 3:
            self.jobsig.set()

    def run(self):
        '''
        handles requests from other Mgrs to write to DB
        '''
        dbgmsg("[DBMGR] DBMgr starting")
        start_time = time()

        while self.donecount < 3:
            if self.jobqueue.empty():
                dbgmsg("[DBMGR] waiting for more database jobs")
                self.jobsig.wait()

            # once signal received, take tasks off queue and process
            while not self.jobqueue.empty():

                # For every 5k queries, end transaction, commit, then restart
                # transaction
                dbgmsg("[DBMGR][DBUP] " + str(self.dbrecordscnt) + " records ready...")

                if self.dbrecordscnt == 0:
                    # this case is only ran once
                    print("[DBUP] Restarting limit count")
                    wsuse_db.starttransaction(self.dbconn)
                elif self.dbrecordscnt >= 5000:
                    print("[DBUP] limit to commit hit")
                    wsuse_db.endtransaction(self.dbconn)
                    self.dbrecordscnt = 0

                task = self.jobqueue.get()
                dbgmsg("[DBMGR] assigning database job: " + str(task[0]))

                if task[0] == "update":
                    self.dbrecordscnt += 1
                    self.writeupdate(task[1][0], task[2], task[3])
                elif task[0] == "binary":
                    self.dbrecordscnt += 1
                    self.writebinary(task[1][0], task[2], task[3], task[4])
                elif task[0] == "symbol":
                    self.dbrecordscnt += 1
                    self.writesym(task[1][0], task[1][1], task[1][2], task[2], task[3], task[4])
                else:
                    dbgmsg("[DBMGR] task unrecognized")

                dbgmsg("[DBMGR] task done, queue at " + str(self.jobqueue.qsize()) + " tasks")

                if self.jobsig.is_set():
                    self.jobsig.clear()

        wsuse_db.endtransaction(self.dbconn, True)
        endtime = time()
        elapsedtime = endtime-start_time
        print("elapsed time for part 4: " + str(elapsedtime))
        dbgmsg("[DBMGR] ****************everything done********************")
